{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BERT Classifier for Product Reviews"]},{"cell_type":"markdown","metadata":{},"source":["## Create Enviroment\n","TODO: Docker machine learning enviroment"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["'''Import Dependencies'''\n","\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"WARNING: Logging before flag parsing goes to stderr.\nW0807 06:29:40.329526 11300 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n"}],"source":["'''Import BERT'''\n","\n","import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["'''Download and Load Data Function'''\n","\n","from tensorflow import keras\n","import os\n","import re\n","\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["'''Set output directory for model and eval files '''\n","\n","train_out = 'train_out'\n","OUTPUT_DIR = train_out\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Download, Clean & Process Data"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","'''Load data from remote into dataframe '''\n","\n","def load_data_from_remote(force_download = False):\n","    \n","    # # load data from url\n","    # dataset = tf.keras.utils.get_file(\n","    #     fname = \"sample_us.tsv\", \n","    #     origin = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv\", \n","    #     extract = False)\n","    \n","    # load data from url\n","    dataset = tf.keras.utils.get_file(\n","        fname = \"amazon_reviews_us_Toys_v1_00.tsv.gz\", \n","        origin = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Toys_v1_00.tsv.gz\", \n","        extract = True)\n","\n","    # # load data from url\n","    # dataset = tf.keras.utils.get_file(\n","    #     fname = \"amazon_reviews_us_Mobile_Electronics_v1_00.tsv.gz\", \n","    #     origin = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Mobile_Electronics_v1_00.tsv.gz\", \n","    #     extract = True)\n","\n","    # # load data from url\n","    # dataset = tf.keras.utils.get_file(\n","    #     fname = \"amazon_reviews_us_Music_v1_00.tsv.gz\", \n","    #     origin = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Music_v1_00.tsv.gz\", \n","    #     extract = True)\n","\n","\n","    # relevant fields from data\n","    fields = ['star_rating', 'review_body']\n","    \n","    # read data to df\n","    df = pd.read_csv(dataset, sep='\\t', header=0, skipinitialspace=True, usecols=fields, encoding='utf-8')\n","\n","\n","    '''Cast column text to lower case'''    \n","\n","    def txt_to_lower(df_name, column_name):    \n","        # create df to merge\n","        df_2 = df_name.drop(column_name, 1)        \n","        # convert review body to lowercase   \n","        df_1 = df_name[column_name].str.lower()\n","        # merge df\n","        df3 =  pd.merge(df_2, df_1, left_index=True, right_index=True)\n","\n","        return df3\n","\n","    \n","    df = txt_to_lower(df, 'review_body')\n","    \n","    # remove null values\n","    df = df.dropna()\n","\n","    return df\n","\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"         star_rating                                        review_body\n565949           5.0          i like that any nfl team can win the game\n3121608          1.0  this item wasn't as good as i thought it was. ...\n2209549          5.0  the head is way more bigger than expected but ...\n470597           5.0     great game, changes the base game considerably\n3809432          5.0  it is what it is - a patch.  its made well, no...\n"}],"source":["'''Spit data to train/test sets '''\n","\n","df = load_data_from_remote()\n","train, test = train_test_split(df, test_size=0.2)\n","\n","# Sample subset of data \n","train = train.sample(10000)\n","test = test.sample(2000) \n","\n","print(train.head(5))\n","\n",""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["'''Assigned input labels for BERT data'''\n","\n","DATA_COLUMN = 'review_body'\n","LABEL_COLUMN = 'star_rating'\n","label_list = [1, 2, 3, 4, 5]\n","\n",""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["'''Transform data into BERT readable objects'''\n","\n","# Use the InputExample class from BERT's run_classifier code to create examples from the data\n","train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n","                                                                   \ttext_a = x[DATA_COLUMN], \n","                                                                   \ttext_b = None, \n","                                                                   \tlabel = x[LABEL_COLUMN]), axis = 1)\n","\n","test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   \ttext_a = x[DATA_COLUMN], \n","                                                                   \ttext_b = None, \n","                                                                   \tlabel = x[LABEL_COLUMN]), axis = 1)\n","\n","\n",""]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"W0807 06:30:22.299050 11300 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\n"}],"source":["'''Transform data to match BERT pre-trained data '''\n","\n","# Load the pre-trained uncased model from tensorflow hub\n","\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","    \"\"\"Get the vocab file and casing info from the Hub module\"\"\"\n","      \n","    with tf.Graph().as_default():\n","        bert_module = hub.Module(BERT_MODEL_HUB)\n","        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","      \n","        with tf.Session() as sess:\n","            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","    \n","    return bert.tokenization.FullTokenizer(\n","        vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","\n","tokenizer = create_tokenizer_from_hub_module()\n","\n",""]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"W0807 06:30:23.812380 11300 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n\n"}],"source":["'''Convert features to BERT understandable'''\n","\n","# set max sequence length\n","MAX_SEQ_LENGTH = 100\n","\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Create the Model"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["'''Create the BERT classification model'''\n","\n","def build_model(predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","\n","    \"\"\"Model Architecture Config\"\"\"\n","\n","    bert_module = hub.Module(\n","        BERT_MODEL_HUB,\n","        trainable=True)\n","\n","    bert_inputs = dict(\n","        input_ids=input_ids,\n","        input_mask=input_mask,\n","        segment_ids=segment_ids)\n","\n","    bert_outputs = bert_module(\n","        inputs=bert_inputs,\n","        signature=\"tokens\",\n","        as_dict=True)\n","\n","\n","    '''Layer Config'''\n","\n","    # Will classify sentence over all labels\n","    output_layer = bert_outputs[\"pooled_output\"]\n","    hidden_size = output_layer.shape[-1].value\n","\n","    # initialise layer weights and bias\n","    output_weights = tf.get_variable(\n","        \"output_weights\", [num_labels, hidden_size],\n","        initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","    output_bias = tf.get_variable(\n","        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","    \n","    '''Output Config'''\n","\n","    with tf.variable_scope(\"loss\"):\n","\n","        # Add layer dropout to 0.1 per layer\n","        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","        logits = tf.nn.bias_add(logits, output_bias)\n","        log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","        # Convert labels into one-hot encoding\n","        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","        \n","        # when predicting model will output label and probability\n","        if predicting:\n","            return (predicted_labels, log_probs)\n","\n","        # When training/eval model will output loss\n","        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","        loss = tf.reduce_mean(per_example_loss)\n","        return (loss, predicted_labels, log_probs)\n","\n","\n",""]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["'''Create the training and prediction functions'''\n","\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps):\n","  \n","    \"\"\"Model function for training, evaluation and predictions\"\"\"\n","\n","    def model_fn(features, labels, mode, params): \n","\n","        input_ids = features[\"input_ids\"]\n","        input_mask = features[\"input_mask\"]\n","        segment_ids = features[\"segment_ids\"]\n","        label_ids = features[\"label_ids\"]\n","\n","        \n","        '''prediction function'''\n","\n","        predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","\n","        '''training and evalution function'''\n","        \n","        if not predicting:\n","\n","            (loss, predicted_labels, log_probs) = build_model(\n","                predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","            train_op = bert.optimization.create_optimizer(\n","                loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","\n","            '''define model eval metrics'''\n","\n","            '''TODO rewrite for multi-class'''\n","\n","            # def metric_fn(label_ids, predicted_labels):\n","            #     accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","            #     f1_score = tf.contrib.metrics.f1_score(\n","            #         label_ids,\n","            #         predicted_labels)\n","            #     auc = tf.metrics.auc(\n","            #         label_ids,\n","            #         predicted_labels)\n","            #     recall = tf.metrics.recall(\n","            #         label_ids,\n","            #         predicted_labels)\n","            #     precision = tf.metrics.precision(\n","            #         label_ids,\n","            #         predicted_labels) \n","            #     true_pos = tf.metrics.true_positives(\n","            #         label_ids,\n","            #         predicted_labels)\n","            #     true_neg = tf.metrics.true_negatives(\n","            #         label_ids,\n","            #         predicted_labels)   \n","            #     false_pos = tf.metrics.false_positives(\n","            #         label_ids,\n","            #         predicted_labels)  \n","            #     false_neg = tf.metrics.false_negatives(\n","            #         label_ids,\n","            #         predicted_labels)\n","            #     return {\n","            #         \"eval_accuracy\": accuracy,\n","            #         \"f1_score\": f1_score,\n","            #         \"auc\": auc,\n","            #         \"precision\": precision,\n","            #         \"recall\": recall,\n","            #         \"true_positives\": true_pos,\n","            #         \"true_negatives\": true_neg,\n","            #         \"false_positives\": false_pos,\n","            #         \"false_negatives\": false_neg\n","            #     }\n","\n","            # eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","\n","            if mode == tf.estimator.ModeKeys.TRAIN:\n","                return tf.estimator.EstimatorSpec(mode=mode,\n","                loss=loss,\n","                train_op=train_op)\n","            else:\n","                return tf.estimator.EstimatorSpec(mode=mode,\n","                loss=loss)\n","                #eval_metric_ops=eval_metrics)\n","        else:\n","            (predicted_labels, log_probs) = build_model(\n","                predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","            predictions = {\n","                'probabilities': log_probs,\n","                'labels': predicted_labels\n","                }\n","        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","    # return the function\n","    return model_fn    \n",""]},{"cell_type":"markdown","metadata":{},"source":["## Set the Training Enviroment"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":"'TODO - save complete trained BERT model'"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["'''Set training hyperpramameters'''\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3.0\n","WARMUP_PROPORTION = 0.1\n","\n","# Model checkpoints\n","SAVE_CHECKPOINTS_STEPS = 500\n","SAVE_SUMMARY_STEPS = 100         \n","\n","'''TODO - save complete trained BERT model'''\n","\n",""]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["'''Define number of step in training process'''\n","\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",""]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["'''Confirm Output Directory & No Checkpoints'''\n","\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n","\n",""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["'''Define the Model Object'''\n","\n","model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})\n","\n",""]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["'''Define the Training Input Function'''\n","\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)  \n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Train the Model"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"W0807 06:30:52.245493 11300 deprecation.py:323] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\nW0807 06:30:58.628640 11300 deprecation.py:506] From <ipython-input-11-7029fd60352c>:43: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nW0807 06:30:58.659676 11300 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n\nW0807 06:30:58.662646 11300 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n\nW0807 06:30:58.669627 11300 deprecation.py:323] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nW0807 06:30:58.684633 11300 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n\nW0807 06:30:58.890811 11300 deprecation.py:323] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nW0807 06:31:02.801814 11300 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\optimization.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n\nC:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\nW0807 07:01:08.752515 11300 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 94 vs previous value: 94. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"},{"name":"stdout","output_type":"stream","text":"Training Classifier\n"},{"name":"stdout","output_type":"stream","text":"Training took time 4:42:43.018258\n"}],"source":["'''Train Model'''\n","\n","print(f'Training Classifier')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print('{}{}'.format(\"Training took time \", datetime.now() - current_time))    \n","\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}