{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BERT Classifier for Product Reviews"]},{"cell_type":"markdown","metadata":{},"source":["## Create Enviroment\n","TODO: Docker machine learning enviroment"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["'''Import Dependencies'''\n","\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"WARNING: Logging before flag parsing goes to stderr.\nW0721 18:38:23.875536 21248 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n"}],"source":["'''Import BERT'''\n","\n","import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["'''Download and Load Data Function'''\n","\n","from tensorflow import keras\n","import os\n","import re\n","\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["'''Set output directory for model and eval files '''\n","\n","train_out = 'train_out'\n","OUTPUT_DIR = train_out\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Download, Clean & Process Data"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","'''Load data from remote into dataframe '''\n","\n","def load_data_from_remote(force_download = False):\n","    \n","    # load data from url\n","    dataset = tf.keras.utils.get_file(\n","        fname = \"sample_us.tsv\", \n","        origin = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv\", \n","        extract = False)\n","    \n","    # relevant fields from data\n","    fields = ['review_id', 'star_rating', 'review_body']\n","    \n","    # read data to df\n","    df = pd.read_csv(dataset, sep='\\t', header=0, skipinitialspace=True, usecols=fields)\n","\n","    return df\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["'''Spit data to train/test sets '''\n","\n","df = load_data_from_remote()\n","train, test = train_test_split(df, test_size=0.2)\n","\n",""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["'''Assigned input labels for BERT data'''\n","\n","DATA_COLUMN = 'review_body'\n","LABEL_COLUMN = 'star_rating'\n","label_list = [1, 2, 3, 4, 5]\n","\n",""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["'''Transform data into BERT readable objects'''\n","\n","# Use the InputExample class from BERT's run_classifier code to create examples from the data\n","train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n","                                                                   \ttext_a = x[DATA_COLUMN], \n","                                                                   \ttext_b = None, \n","                                                                   \tlabel = x[LABEL_COLUMN]), axis = 1)\n","\n","test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   \ttext_a = x[DATA_COLUMN], \n","                                                                   \ttext_b = None, \n","                                                                   \tlabel = x[LABEL_COLUMN]), axis = 1)\n","\n","\n",""]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"W0721 18:38:27.393238 21248 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\n"}],"source":["'''Transform data to match BERT pre-trained data '''\n","\n","# Load the pre-trained uncased model from tensorflow hub\n","\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","    \"\"\"Get the vocab file and casing info from the Hub module\"\"\"\n","      \n","    with tf.Graph().as_default():\n","        bert_module = hub.Module(BERT_MODEL_HUB)\n","        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","      \n","        with tf.Session() as sess:\n","            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","    \n","    return bert.tokenization.FullTokenizer(\n","        vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()\n","\n",""]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"W0721 18:38:27.498947 21248 deprecation_wrapper.py:119] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bert\\run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n\n"}],"source":["'''Convert features to BERT understandable'''\n","\n","# set max sequence length\n","MAX_SEQ_LENGTH = 100\n","\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Create the Model"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["'''Create the BERT classification model'''\n","\n","def build_model(predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","\n","    \"\"\"Model Architecture Config\"\"\"\n","\n","    bert_module = hub.Module(\n","        BERT_MODEL_HUB,\n","        trainable=True)\n","\n","    bert_inputs = dict(\n","        input_ids=input_ids,\n","        input_mask=input_mask,\n","        segment_ids=segment_ids)\n","\n","    bert_outputs = bert_module(\n","        inputs=bert_inputs,\n","        signature=\"tokens\",\n","        as_dict=True)\n","\n","\n","    '''Layer Config'''\n","\n","    # Will classify sentence over all labels\n","    output_layer = bert_outputs[\"pooled_output\"]\n","    hidden_size = output_layer.shape[-1].value\n","\n","    # initialise layer weights and bias\n","    output_weights = tf.get_variable(\n","        \"output_weights\", [num_labels, hidden_size],\n","        initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","    output_bias = tf.get_variable(\n","        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","    \n","    '''Output Config'''\n","\n","    with tf.variable_scope(\"loss\"):\n","\n","        # Add layer dropout to 0.1 per layer\n","        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","        logits = tf.nn.bias_add(logits, output_bias)\n","        log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","        # Convert labels into one-hot encoding\n","        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","        \n","        # when predicting model will output label and probability\n","        if predicting:\n","            return (predicted_labels, log_probs)\n","\n","        # When training/eval model will output loss\n","        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","        loss = tf.reduce_mean(per_example_loss)\n","        return (loss, predicted_labels, log_probs)\n","\n","\n",""]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":[" '''Create the training and prediction functions'''\n","\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps):\n","  \n","    \"\"\"Model function for training, evaluation and predictions\"\"\"\n","\n","    def model_fn(features, labels, mode, params): \n","\n","        input_ids = features[\"input_ids\"]\n","        input_mask = features[\"input_mask\"]\n","        segment_ids = features[\"segment_ids\"]\n","        label_ids = features[\"label_ids\"]\n","\n","        \n","        '''prediction function'''\n","\n","        predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","\n","        '''training and evalution function'''\n","        \n","        if not predicting:\n","\n","            (loss, predicted_labels, log_probs) = build_model(\n","                predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","            train_op = bert.optimization.create_optimizer(\n","                loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","\n","            if mode == tf.estimator.ModeKeys.TRAIN:\n","                return tf.estimator.EstimatorSpec(mode=mode,\n","                loss=loss,\n","                train_op=train_op)\n","            else:\n","                return tf.estimator.EstimatorSpec(mode=mode,\n","                loss=loss,\n","                eval_metric_ops=eval_metrics)\n","        else:\n","            (predicted_labels, log_probs) = build_model(\n","                predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","            predictions = {\n","                'probabilities': log_probs,\n","                'labels': predicted_labels\n","                }\n","        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","    # return the function\n","    return model_fn    \n",""]},{"cell_type":"markdown","metadata":{},"source":["## Set the Training Enviroment"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":"'TODO - save complete trained BERT model'"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["'''Set training hyperpramameters'''\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3.0\n","WARMUP_PROPORTION = 0.1\n","\n","# Model checkpoints\n","SAVE_CHECKPOINTS_STEPS = 500\n","SAVE_SUMMARY_STEPS = 100         \n","\n","'''TODO - save complete trained BERT model'''\n","\n",""]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["'''Define number of step in training process'''\n","\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",""]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["'''Confirm Output Directory & No Checkpoints'''\n","\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n","\n",""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["'''Define the Model Object'''\n","\n","model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})\n","\n",""]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["'''Define the Training Input Function'''\n","\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)  \n",""]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"W0721 18:38:33.918218 21248 deprecation.py:323] From C:\\Users\\ehshan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"},{"name":"stdout","output_type":"stream","text":"Trainig Classifier\n"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-18-c62b03924f75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Trainig Classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training took time \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1156\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1186\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1188\u001b[1;33m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1189\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-12-9451dfec67df>\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode, params)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m            (loss, predicted_labels, log_probs) = build_model(\n\u001b[1;32m---> 24\u001b[1;33m                predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m            train_op = bert.optimization.create_optimizer(\n","\u001b[1;32m<ipython-input-11-7029fd60352c>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(predicting, input_ids, input_mask, segment_ids, labels, num_labels)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tokens\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         as_dict=True)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    256\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_prepare_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36mcreate_apply_graph\u001b[1;34m(self, signature, input_tensors, name)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mmeta_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         import_scope=relative_scope_name)\n\u001b[0m\u001b[0;32m    562\u001b[0m     fix_colocation_after_import(input_map=feed_map,\n\u001b[0;32m    563\u001b[0m                                 absolute_import_scope=absolute_scope_name)\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[0;32m   1447\u001b[0m   return _import_meta_graph_with_return_elements(meta_graph_or_file,\n\u001b[0;32m   1448\u001b[0m                                                  \u001b[0mclear_devices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m                                                  **kwargs)[0]\n\u001b[0m\u001b[0;32m   1450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m_import_meta_graph_with_return_elements\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\u001b[0m\n\u001b[0;32m   1471\u001b[0m           \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m           \u001b[0mreturn_elements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_elements\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1473\u001b[1;33m           **kwargs))\n\u001b[0m\u001b[0;32m   1474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m   saver = _create_saver_from_imported_meta_graph(meta_graph_def, import_scope,\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mimport_scoped_meta_graph_with_return_elements\u001b[1;34m(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[0mproducer_op_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproducer_op_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m         return_elements=return_elements)\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[1;31m# TensorFlow versions before 1.9 (not inclusive) exported SavedModels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;31m# TODO(skyewm): avoid sending serialized FunctionDefs back to the TF_Graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m     \u001b[0m_ProcessNewOps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36m_ProcessNewOps\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[0mcolocation_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0mnew_op\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_new_tf_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[0moriginal_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mnew_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_add_new_tf_operations\u001b[1;34m(self, compute_devices)\u001b[0m\n\u001b[0;32m   3749\u001b[0m     new_ops = [\n\u001b[0;32m   3750\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_from_tf_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3751\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mc_op\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_tf_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3752\u001b[0m     ]\n\u001b[0;32m   3753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3749\u001b[0m     new_ops = [\n\u001b[0;32m   3750\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_from_tf_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3751\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mc_op\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_tf_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3752\u001b[0m     ]\n\u001b[0;32m   3753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_from_tf_operation\u001b[1;34m(self, c_op, compute_device)\u001b[0m\n\u001b[0;32m   3639\u001b[0m     \"\"\"\n\u001b[0;32m   3640\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_not_finalized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3641\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3642\u001b[0m     \u001b[1;31m# If a name_scope was created with ret.name but no nodes were created in it,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3643\u001b[0m     \u001b[1;31m# the name will still appear in _names_in_use even though the name hasn't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2031\u001b[0m     output_types = [\n\u001b[0;32m   2032\u001b[0m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationOutputType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2033\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2034\u001b[0m     ]\n\u001b[0;32m   2035\u001b[0m     self._outputs = [\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2031\u001b[0m     output_types = [\n\u001b[0;32m   2032\u001b[0m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationOutputType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2033\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2034\u001b[0m     ]\n\u001b[0;32m   2035\u001b[0m     self._outputs = [\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\u001b[0m in \u001b[0;36mtf_output\u001b[1;34m(c_op, index)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mWrapped\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m   \"\"\"\n\u001b[1;32m--> 186\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m   \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m   \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m         \u001b[0mthis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_TF_Output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1412\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["'''Train Model'''\n","\n","print(f'Trainig Classifier')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print('{}{}'.format(\"Training took time \", datetime.now() - current_time))    \n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}